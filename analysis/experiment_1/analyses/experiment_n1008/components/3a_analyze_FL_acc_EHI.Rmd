```{r}
## Setup
acc_subject_sub <- acc_subject |> filter(handedness == handedness_subgroup)
aah_sub <- aah |> filter(handedness == handedness_subgroup)
acc_1_sub <- acc_1 |> filter(handedness == handedness_subgroup)
```

#### Accuracy

##### Plots
```{r}
fig_path_acc_4 <- here(fig_dir, str_c("acc_4_", subgroup_label, ".png"))
fig_path_acc_4_wide <- here(fig_dir, str_c("acc_4_wide_", subgroup_label, ".png"))

if (use_cached_rtfigs == FALSE) {
acc_descriptive <- acc_subject_sub |>
      group_by(field, level) |> 
      summarize(mean = mean(acc))

g <- ggplot(acc_subject_sub, aes(
  x = level,
  y = acc,
  fill = level,
  color = level
)) +
  geom_quasirandom(alpha = .1, show.legend = F) +
  geom_boxplot(
    alpha = 0.5,
    size = 0.3,
    varwidth = F,
    outlier.shape = NA,
    color = "gray20",
    show.legend = F
  ) +
  stat_summary(
    fun.data = mean_cl_normal,
    fun.args = list(conf.int = 0.95),
    geom = "errorbar",
    position = "dodge",
    linetype = 1,
    color = "gray5",
    width = .2,
    # size = point_size / 5,
    show.legend = F
  ) +
  geom_point(
    data = acc_descriptive,
    aes(y = mean),
    color = "black",
    shape = 21,
    show.legend = F
  ) +
  scale_y_continuous(minor_breaks = seq(-100, 100, 5),
                     breaks = seq(-100, 100, 10)) +
  facet_wrap( ~ field) +
  labs(title = "Per-subject accuracy", x = "Level", y = "Accuracy (% correct)")

g <- g |> gg_style_means() |> gg_color()
ggsave(fig_path_acc_4, g, "png", height = 4, width = 4)

ggsave(fig_path_acc_4_wide, g, "png", height = 4, width = 8)

g_acc_4 <- g
}

include_graphics(fig_path_acc_4_wide)
```

```{r}
fig_path_acc_2 <- here(fig_dir, str_c("acc_2_", subgroup_label, ".png"))

if (use_cached_rtfigs == FALSE) {
## Make a table showing:
## For each subject and field, the difference in median acc for:
## Global - Local
acc_2 <- acc_subject_sub |> 
  pivot_wider(names_from = c(level),
              values_from = acc) |> 
  mutate(Global_Bias = Global - Local)

acc_descriptive <- acc_2 |>
  group_by(field) |>
  summarize(
    median = median(Global_Bias),
    mean = mean(Global_Bias),
    SE = sd(Global_Bias) / sqrt(length((Global_Bias)))
  )

g <- ggplot(acc_2, aes(x = field,
                      y = Global_Bias, color)) +
  geom_quasirandom(
    alpha = .1, show.legend = F,
    color = plot_color) +
  geom_boxplot(
    alpha = 0.5,
    size = 0.3,
    varwidth = F,
    outlier.shape = NA,
    fill = plot_color,
    color = "gray20",
    show.legend = F
  ) +
  stat_summary(
    fun.data = mean_cl_normal,
    fun.args = list(conf.int = 0.95),
    geom = "errorbar",
    position = "dodge",
    linetype = 1,
    color = "gray5",
    width = .2,
    show.legend = F
  ) +
  geom_point(
    data = acc_descriptive,
    aes(y = mean),
    fill = plot_color,
    shape = 21,
    show.legend = F
  ) +
  scale_y_continuous(minor_breaks = seq(-100 , 100, 5),
                     breaks = seq(-100, 100, 10)) +
  labs(title = "Global bias (Accuracy)", x = "Level", y = "Local - Global Accuracy (% correct)")

g <- g |> gg_style_means()
ggsave(fig_path_acc_2, g, "png", height = 4, width = 4)
g_acc_2 <- g
}

#include_graphics(fig_path_acc_2)
```

```{r}
fig_path_ga1 <- here(fig_dir, str_c("ga1_", subgroup_label, ".png"))

if (use_cached_accfigs == FALSE) {
acc_descriptive <- acc_1_sub |>
  group_by(all_one_group) |> 
  summarize(
    median = median(LVF_Global_Bias),
    mean = mean(LVF_Global_Bias),
    SE = sd(LVF_Global_Bias) / sqrt(length((LVF_Global_Bias)))
  )

g <- ggplot(acc_1_sub, aes(
  x = all_one_group,
  y = LVF_Global_Bias
)) +
  geom_quasirandom(
    alpha = .1, show.legend = F,
    color = plot_color) +
  geom_boxplot(
    alpha = 0.5,
    size = 0.3,
    varwidth = F,
    outlier.shape = NA,
    color = "gray20",
    fill = plot_color,
    show.legend = F
  ) +
  stat_summary(
    fun.data = mean_cl_normal,
    fun.args = list(conf.int = 0.95),
    geom = "errorbar",
    position = "dodge",
    linetype = 1,
    color = "gray5",
    width = .2,
    # size = point_size / 5,
    show.legend = F
  ) +
  geom_point(
    data = acc_descriptive,
    aes(y = mean),
    fill = plot_color,
    color = "black",
    shape = 21,
    show.legend = F
  ) +
  scale_y_continuous(minor_breaks = seq(-100 , 100, 5),
                     breaks = seq(-100, 100, 10)) +
  theme(axis.text.x = element_blank()) +
  labs(title = "LVF>RVF Global Bias (Acc.)", x = "Level", y = "LVF-RVF, Global - Local (% correct)")

g <- g |> gg_style_means() |> gg_color() +
  theme(axis.text.x = element_blank(), aspect.ratio = 4/1)
ggsave(fig_path_ga1, g, "png", height = 4, width = 4)
g_acc_1 <- g
}

#include_graphics(fig_path_ga1)
```

```{r}
fig_path_acc_21 <- here(fig_dir, str_c("acc_combo_21_", subgroup_label, ".png"))

if (use_cached_rtfigs == FALSE) {
  g_acc_1_padded <- g_acc_1 + theme(plot.margin = 
                              margin(t = 30, r = 50, b = 10, l = 50, unit = "pt"))
  g_acc_21 <- g_acc_2 + g_acc_1_padded
  g_acc_21
  ggsave(fig_path_acc_21, g_acc_21, "png", height = 4, width = 8)
}

include_graphics(fig_path_acc_21)
```

##### Statistics

Accuracy is modeled as a binomial effect of field and level, using binary correct/incorrect data from every target-present trial:
<br>
<br>
`glmer( correct ~ field + level + field:level + (1 | subject), family = "binomial" )`
<br>
<br>
```{r}
## Make a binomial logistic model using data from every trial.
## Fixed effects: field, level (and their interaction)
## Random effects: subject.
## correct ~ field + level + field:level + (1 | subject)
acc_model <- glmer(correct ~ field:level + field + level + (1 | subject),
                   data = aah_sub,
                   family = "binomial")

if (use_cached_model_acc == FALSE) {
  ## Create emmeans model object, and manually cache it.
  acc_emm <- emmeans(acc_model, ~ field * level)
  
  ## Manually cache model
  saveRDS(acc_emm, here(manual_cache_dir, subgroup_label, "acc_emm.rds"))
  
} else if (use_cached_model_acc == TRUE) {
  ## Load cached model
  acc_emm <- readRDS(here(manual_cache_dir, subgroup_label, "acc_emm.rds"))
}
```
<!-- Test for field x level interaction, using the anova() function: is the interaction model's fit significantly different from the no-interaction model's fit? -->
<br>
```{r}
## TODO: figure out why this table doesn't render in the knit document.
## Use anova() to test 2-way interaction effect.
interaction_stats <-
  function(model_with_interaction,
           model_with_no_interaction) {
    return(anova(model_with_interaction, model_with_no_interaction))
  }

acc_model_no_interaction <- update(acc_model, . ~ . - field:level)
interaction_anova <- interaction_stats(acc_model, acc_model_no_interaction)
#interaction_anova
interaction_anova |>
  as_tibble() |>
  rename(p.value = `Pr(>Chisq)`) |> 
  format_p.value() |> 
  pretty_table() |> 
  tab_header(title = "Field by level interaction (Accuracy)", 
             subtitle = "ANOVA: compare models with vs. without interaction term") 
```
<br>
<!-- Test for field x level interaction, using emmeans() - is the model's interaction effect estimate significantly different from zero? -->
```{r}
## Is there an interaction of field x level?
## Use an emmeans contrast
acc_interaction_emm <- acc_emm |>
  contrast(interaction = c("consec")) |>
  summary(infer = T, type = "response")
#acc_interaction_emm

acc_interaction_emm |>
  as_tibble() |>
  format_p.value() |> 
  pretty_table() |>
  tab_header(title = "Field by level interaction (Accuracy)",
             subtitle = "Compare effect estimate to zero with emmeans()") |>
  tab_footnote(footnote =  "Backtransformed to odds ratio from log odds ratio (tests are performed on log odds ratio scale). A ratio > 1 means global bias is stronger in the LVF, as predicted for right handers.",
               locations = cells_column_labels(columns = odds.ratio)) |>
  tab_footnote(footnote = "I don't understand why df is 'Inf' here, but I think it is expected when emmeans does logistic regression. See emmeans FAQ: https://cran.r-project.org/web/packages/emmeans/vignettes/FAQs.html#asymp.",
               locations = cells_column_labels(columns = df)) |>
  tab_footnote(footnote = "Confidence level: 95%",
               locations = cells_column_labels(columns = asymp.LCL)) |>
  tab_footnote(footnote = "Two-sided",
               locations = cells_column_labels(columns = p.value))
```
<br>
```{r}
acc_field_bias_emm <- acc_emm |>
  contrast("pairwise") |>
  summary(infer = T, adjust = "none", type = "response")
#acc_field_bias_emm

acc_field_bias <- acc_field_bias_emm |>
  as_tibble() |>
  filter(contrast %in%
           c("LVF Global / LVF Local", "RVF Global / RVF Local"))
#acc_field_bias

acc_field_bias |>
  format_p.value() |> 
  pretty_table() |>
  tab_header(title = "Global bias by field (Accuracy)") |>
  tab_footnote(footnote =  "Backtransformed to odds ratio from log odds ratio (tests are performed on log odds ratio scale). A ratio > 1 means global bias (more correct responses for global).",
               locations = cells_column_labels(columns = odds.ratio)) |>
  tab_footnote(footnote = "Confidence level: 95%",
               locations = cells_column_labels(columns = asymp.LCL)) |>
  tab_footnote(footnote = "Two-sided, uncorrected",
               locations = cells_column_labels(columns = p.value))
```
<br>
```{r}
acc_modelled <- summary(acc_emm, type = "response")
# acc_modelled
acc_modelled |>
  as_tibble() |> 
  arrange(field) |> 
  pretty_table() |>
  tab_header(title = "Accuracy estimates by field and level (from model)") |>
  tab_footnote(footnote = "Back-transformed to probability (% correct) from logit scale",
               locations = cells_column_labels(columns = prob)) |>
  tab_footnote(footnote = "Confidence level: 95%",
               locations = cells_column_labels(columns = asymp.LCL))
```
<br>
```{r}
acc_descriptive <- aah_sub |>
      group_by(level, field, subject) |>
      summarize(
        total_responses = n(),
        n_present_resp = sum(correct),
        n_absent_resp = total_responses - n_present_resp,
        n_correct = sum(correct),
        percent_correct = 100 * (n_correct / total_responses)
      ) |> 
      group_by(field, level) |> 
      summarize(mean_subject_percent_correct = mean(percent_correct))
#acc_descriptive
    
acc_descriptive |>
  pretty_table() |>
  tab_header(title = "Accuracy estimates by field and level (descriptive)")
```
<br>

